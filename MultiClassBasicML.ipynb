{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5afa7042",
   "metadata": {},
   "source": [
    "#### Now create a multiclass problem \n",
    "Here we will include all classes so basically we have to load the data again, it will almost be the same code as for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abbcf5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd, norm\n",
    "#from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from PIL import Image\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import datasets, svm, metrics\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#Import naive bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "#import Knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Import confusion matrixdisplay\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "#For truncated svd, we need to import the base estimator and classifier mixin\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "#For multilabel classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac943498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = Image.open(f'{base_dir}{path}')\n",
    "    #Resize the image to 320x320\n",
    "    img = img.resize((320, 320))\n",
    "    img = np.array(img)\n",
    "    img = np.array(img)\n",
    "    img = img.flatten()\n",
    "    #img = img.reshape((-1,1))\n",
    "    return img\n",
    "\n",
    "def one_hot_encode(label):\n",
    "    # One hot encoding\n",
    "    place_holder = [0, 0, 0, 0, 0]\n",
    "    if 'CrackA' in label:\n",
    "        place_holder[0] = 1\n",
    "    if 'CrackB' in label:\n",
    "        place_holder[1] = 1\n",
    "    if 'CrackC' in label:\n",
    "        place_holder[2] = 1\n",
    "    if 'FingerFailure' in label:\n",
    "        place_holder[3] = 1\n",
    "    if 'Negative' in label:\n",
    "        place_holder[4] = 1\n",
    "    return place_holder\n",
    "\n",
    "def get_images(data, M=102,train=True):\n",
    "    # Load the data such that the collumns of X is the image as a vector\n",
    "    # Initialize np array of size (320*320,len(data))\n",
    "    X = [] #np.zeros(((320 * 320),M*2))\n",
    "    y = []#[None] * (M*2)\n",
    "    neg_count = 0\n",
    "    pos_count = 0\n",
    "    \n",
    "    for (i, row) in tqdm(data.iterrows()):\n",
    "        #Get the label\n",
    "        label = ast.literal_eval(row['Label'])\n",
    "        lab_encoding = one_hot_encode(label)\n",
    "        \n",
    "        if lab_encoding[4] == 1 and neg_count < M:\n",
    "            im = load_image(row['ImageDir'])\n",
    "            X.append(im)\n",
    "            y.append(lab_encoding)\n",
    "            if train:\n",
    "                neg_count += 1\n",
    "        elif not lab_encoding[4]:\n",
    "            im = load_image(row['ImageDir'])\n",
    "            X.append(im)\n",
    "            y.append(lab_encoding)\n",
    "            if train:\n",
    "                pos_count += 1\n",
    "        elif neg_count >= M and pos_count >= M:\n",
    "            print(\"What\")\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "    X = np.array(X)\n",
    "    X = X.T #We want the collumns to be the images\n",
    "    return X, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79026a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('/Users/madsandersen/PycharmProjects/BscProjektData/BachelorProject/Data/VitusData/Train.csv')\n",
    "train_data = train_data.drop(['Unnamed: 0'], axis=1)\n",
    "test_data = pd.read_csv('/Users/madsandersen/PycharmProjects/BscProjektData/BachelorProject/Data/VitusData/Val.csv')\n",
    "test_data = test_data.drop(['Unnamed: 0'], axis=1)\n",
    "base_dir = '/Users/madsandersen/PycharmProjects/BscProjektData/BachelorProject/Data/'\n",
    "\n",
    "# Training data size\n",
    "M = 60 # Number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4bc6b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8879it [00:01, 7889.20it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7211it [00:27, 262.48it/s]\n"
     ]
    }
   ],
   "source": [
    "#Create the X and y matrices\n",
    "X_train,y_train = get_images(train_data,train=True)\n",
    "X_test,y_test = get_images(test_data,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ddff7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102400, 204)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42afeaa5",
   "metadata": {},
   "source": [
    "### Multilabel classification\n",
    "Fit at binary classifier to each class to test if they belong to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38594c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = MultiOutputClassifier(svm.SVC(kernel='linear', C=0.01)).fit(X_train.T, y_train)\n",
    "clf = MultiOutputClassifier(AdaBoostClassifier(n_estimators=100, random_state=0)).fit(X_train.T, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca191e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc73624a",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_predictions = {\n",
    "                       'predA':preds[:,0],\n",
    "                       'predB':preds[:,1],\n",
    "                       'predC':preds[:,2],\n",
    "                       'predFF': preds[:,3],\n",
    "                       'predNeg':preds[:,4]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e70394",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,5, figsize=(5,15))\n",
    "\n",
    "for idx,lab in enumerate(binary_predictions.keys()):\n",
    "    y_hat = binary_predictions[lab]\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(y_test[:,idx], y_hat)\n",
    "    disp.plot(ax=axes.flat[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2138f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37064678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
